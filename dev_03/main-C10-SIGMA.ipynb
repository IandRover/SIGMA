{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ffa0c9f-8276-4e73-b6a8-bf33d01039d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = \"dcf9600e0485401cbb0ddbb0f7be1c70f96b32ef\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "import wandb\n",
    "from sigma_layer import SigmaLinear, SigmaConv, SigmaView\n",
    "from utils import get_dataset, gradient_centralization, normalize_along_axis, get_activation_function, compute_SCL_loss\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f367862f-05b5-4c98-b3be-7a36a686df88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: CIFAR10_SIGMA_conv32-actelu_SGD_1_2023\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "No LN1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:13<21:53, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train loss 2.2178 | val loss 2.0178 | val acc 30.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:27<22:11, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train loss 2.0582 | val loss 1.7265 | val acc 39.2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:41<22:14, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | train loss 1.8743 | val loss 1.6028 | val acc 44.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:54<21:59, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | train loss 1.8098 | val loss 1.6477 | val acc 41.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [01:08<21:59, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | train loss 1.7366 | val loss 1.5404 | val acc 45.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [01:22<21:26, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | train loss 1.6680 | val loss 1.5069 | val acc 47.3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:35<20:54, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | train loss 1.5717 | val loss 1.4420 | val acc 49.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:48<20:34, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | train loss 1.5261 | val loss 1.2913 | val acc 55.5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [02:02<20:31, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | train loss 1.3500 | val loss 1.2612 | val acc 55.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [02:15<20:13, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | train loss 1.3497 | val loss 1.2635 | val acc 55.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [02:29<20:05, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss 1.3222 | val loss 1.2236 | val acc 57.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [02:42<19:53, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train loss 1.2760 | val loss 1.2085 | val acc 58.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [02:56<19:43, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train loss 1.2610 | val loss 1.1985 | val acc 58.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [03:10<19:39, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train loss 1.2741 | val loss 1.1896 | val acc 58.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [03:24<19:25, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train loss 1.2365 | val loss 1.1932 | val acc 58.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [03:37<18:59, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train loss 1.2088 | val loss 1.1761 | val acc 59.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [03:50<18:40, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train loss 1.1978 | val loss 1.1789 | val acc 59.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [04:04<18:16, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train loss 1.1811 | val loss 1.1508 | val acc 60.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [04:17<18:01, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train loss 1.1924 | val loss 1.1621 | val acc 59.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [04:30<17:44, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train loss 1.1503 | val loss 1.1522 | val acc 60.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [04:43<17:32, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train loss 1.1603 | val loss 1.1463 | val acc 60.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [04:57<17:26, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | train loss 1.1646 | val loss 1.1492 | val acc 60.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [05:10<17:05, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | train loss 1.1628 | val loss 1.1445 | val acc 61.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [05:24<16:55, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | train loss 1.1409 | val loss 1.1495 | val acc 60.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [05:37<16:40, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | train loss 1.1320 | val loss 1.1449 | val acc 60.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [05:50<16:22, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | train loss 1.1073 | val loss 1.1573 | val acc 60.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [06:03<16:06, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | train loss 1.1113 | val loss 1.1571 | val acc 59.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [06:16<15:50, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | train loss 1.1111 | val loss 1.1413 | val acc 60.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [06:30<15:42, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | train loss 1.0936 | val loss 1.1381 | val acc 60.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [06:43<15:30, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | train loss 1.0836 | val loss 1.1456 | val acc 60.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [06:56<15:12, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | train loss 1.1069 | val loss 1.1391 | val acc 61.4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [07:09<14:56, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | train loss 1.1202 | val loss 1.1420 | val acc 61.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [07:22<14:41, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | train loss 1.0922 | val loss 1.1413 | val acc 60.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [07:35<14:29, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | train loss 1.0895 | val loss 1.1296 | val acc 60.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [07:49<14:21, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | train loss 1.0668 | val loss 1.1235 | val acc 62.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [08:02<14:11, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | train loss 1.0702 | val loss 1.1329 | val acc 61.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [08:16<13:56, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | train loss 1.0602 | val loss 1.1486 | val acc 60.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [08:29<13:50, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | train loss 1.0604 | val loss 1.1280 | val acc 61.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [08:43<13:43, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | train loss 1.0781 | val loss 1.1342 | val acc 61.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [08:57<13:31, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | train loss 1.0485 | val loss 1.1252 | val acc 61.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [09:10<13:11, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | train loss 1.0445 | val loss 1.1327 | val acc 61.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [09:23<12:53, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | train loss 1.0506 | val loss 1.1432 | val acc 61.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [09:36<12:38, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | train loss 1.0403 | val loss 1.1525 | val acc 60.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [09:49<12:24, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | train loss 1.0327 | val loss 1.1267 | val acc 61.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [10:03<12:09, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | train loss 1.0465 | val loss 1.1212 | val acc 62.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [10:16<11:57, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | train loss 1.0422 | val loss 1.1249 | val acc 62.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [10:29<11:41, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | train loss 1.0604 | val loss 1.1282 | val acc 61.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [10:42<11:30, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | train loss 1.0462 | val loss 1.1136 | val acc 62.3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [10:56<11:20, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | train loss 1.0243 | val loss 1.1010 | val acc 62.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [11:09<11:08, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | train loss 1.0269 | val loss 1.1512 | val acc 60.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [11:22<10:50, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | train loss 1.0425 | val loss 1.1344 | val acc 61.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [11:36<10:36, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | train loss 1.0211 | val loss 1.1241 | val acc 61.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [11:49<10:20, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | train loss 1.0254 | val loss 1.1193 | val acc 62.2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [12:02<10:06, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | train loss 1.0279 | val loss 1.1288 | val acc 61.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [12:15<09:52, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | train loss 1.0185 | val loss 1.1110 | val acc 62.2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [12:28<09:39, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | train loss 1.0276 | val loss 1.1271 | val acc 61.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [12:41<09:28, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | train loss 1.0374 | val loss 1.1207 | val acc 62.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [12:55<09:13, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | train loss 1.0030 | val loss 1.1086 | val acc 62.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [13:08<09:00, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | train loss 1.0169 | val loss 1.1363 | val acc 61.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [13:21<08:45, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | train loss 0.9875 | val loss 1.1217 | val acc 62.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [13:34<08:32, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | train loss 0.9929 | val loss 1.1068 | val acc 62.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [13:47<08:18, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | train loss 1.0296 | val loss 1.1210 | val acc 61.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [14:00<08:05, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | train loss 0.9823 | val loss 1.1080 | val acc 62.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [14:13<07:51, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | train loss 0.9786 | val loss 1.1103 | val acc 62.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [14:26<07:39, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | train loss 0.9836 | val loss 1.1443 | val acc 61.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [14:40<07:27, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | train loss 1.0044 | val loss 1.1047 | val acc 62.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [14:53<07:15, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | train loss 0.9885 | val loss 1.1099 | val acc 62.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [15:06<07:01, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | train loss 0.9599 | val loss 1.1189 | val acc 62.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [15:20<06:54, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | train loss 1.0217 | val loss 1.1041 | val acc 62.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [15:34<06:51, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | train loss 0.9865 | val loss 1.1017 | val acc 63.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [15:48<06:40, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | train loss 1.0020 | val loss 1.1023 | val acc 63.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [16:02<06:23, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | train loss 1.0102 | val loss 1.1420 | val acc 61.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [16:15<06:08, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | train loss 0.9916 | val loss 1.1052 | val acc 63.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [16:29<05:52, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | train loss 0.9898 | val loss 1.1031 | val acc 62.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [16:42<05:38, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | train loss 0.9998 | val loss 1.1078 | val acc 62.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [16:55<05:23, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | train loss 0.9779 | val loss 1.1026 | val acc 63.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [17:07<05:24, 13.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 168\u001b[0m\n\u001b[1;32m    166\u001b[0m val_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSIGMA\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 168\u001b[0m     activations \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mto(device), detach_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    169\u001b[0m     _, loss_item \u001b[39m=\u001b[39m criteria(activations, signals, target\u001b[39m.\u001b[39mto(device), method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlocal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[39melif\u001b[39;00m args\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBP\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 88\u001b[0m, in \u001b[0;36mSigmaModel_SimpleCNN.forward\u001b[0;34m(self, x, detach_grad, return_activations)\u001b[0m\n\u001b[1;32m     86\u001b[0m a2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(a1, detach_grad)\n\u001b[1;32m     87\u001b[0m a2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mview1(a2, detach_grad)\n\u001b[0;32m---> 88\u001b[0m a3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(a2, detach_grad)\n\u001b[1;32m     89\u001b[0m a4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(a3, detach_grad)\n\u001b[1;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m [a1, a2, a3, a4]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/SIGMA/sigma_layer.py:23\u001b[0m, in \u001b[0;36mSigmaLinear.forward\u001b[0;34m(self, x, detach_grad)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, detach_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m detach_grad: x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_act(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_layer(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "# Training scheme group\n",
    "method_parser = parser.add_argument_group(\"Method\")\n",
    "method_parser.add_argument('--method', type=str, default='SIGMA', choices=['SIGMA', 'BP', 'FA'])\n",
    "method_parser.add_argument('--architecture', type=str, default='lenet', choices=['lenet', 'vgg'])\n",
    "method_parser.add_argument('--actfunc', type=str, default='elu', choices=['tanh', 'elu', 'relu'])\n",
    "method_parser.add_argument('--conv_dim', type=int, default=32, choices=[32, 64])\n",
    "# Dataset group\n",
    "dataset_parser = parser.add_argument_group('Dataset')\n",
    "dataset_parser.add_argument('--dataset', type=str, default='CIFAR10', choices=['MNIST', 'CIFAR10'])\n",
    "dataset_parser.add_argument('--batchsize', type=int, default=64)\n",
    "dataset_parser.add_argument('--splitratio', type=float, default=0.2)\n",
    "# Training group # LR, optimizer, weight_decay, momentum\n",
    "training_parser = parser.add_argument_group('Training')\n",
    "training_parser.add_argument('--epochs', type=int, default=100)\n",
    "training_parser.add_argument('--lr', type=float, default=1)\n",
    "training_parser.add_argument('--optimizer', type=str, default='SGD', choices=['RMSprop', 'Adam', 'SGD'])\n",
    "# Seed group\n",
    "seed_parser = parser.add_argument_group('Seed')\n",
    "seed_parser.add_argument('--seed', type=int, default=2023)\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "# Set run_name\n",
    "run_name = f\"{args.dataset}_{args.method}_conv{args.conv_dim}-act{args.actfunc}_{args.optimizer}_{args.lr}_{args.seed}\"\n",
    "time_stamp = datetime.datetime.now().strftime(\"%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Set wandb\n",
    "wandb.init(\n",
    "    project=\"opt-sigma\",\n",
    "    name=run_name,\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"algorithm\": args.method,\n",
    "    \"architecture\": \"SimpleCNN\",\n",
    "    \"dataset\": args.dataset,\n",
    "    \"epochs\": args.epochs,\n",
    "    \"lr\": args.lr,\n",
    "    \"optimizer\": args.optimizer,\n",
    "    \"seed\": args.seed,\n",
    "    \"conv_dim\": args.conv_dim,\n",
    "    \"actfunc\": args.actfunc,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Run name: {run_name}\")\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(args.seed), np.random.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda\")\n",
    "\n",
    "# Get dataset\n",
    "train_loader, val_loader, test_loader = get_dataset(args)\n",
    "\n",
    "class SigmaModel_SimpleCNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SigmaModel_SimpleCNN, self).__init__()\n",
    "        if args.dataset == \"CIFAR10\":\n",
    "            self.LN1 = torch.nn.LayerNorm((3,32,32), elementwise_affine=False) \n",
    "            self.conv1 = SigmaConv(args, 3, 32, 5, 3, 2)\n",
    "            self.conv2 = SigmaConv(args, 32, 64, 3, 3, 2)\n",
    "            self.view1 = SigmaView((64, 8, 8), 64 * 8 * 8)\n",
    "            self.fc1 = SigmaLinear(args, 64 * 8 * 8, 128)\n",
    "            self.fc2 = SigmaLinear(args, 128, 10)\n",
    "            \n",
    "        elif args.dataset == \"MNIST\":\n",
    "            if args.architecture == \"lenet\":\n",
    "                self.LN1 = torch.nn.LayerNorm((1,28,28), elementwise_affine=False) \n",
    "                self.conv1 = SigmaConv(args, 1, 32, 5, 2, 3)\n",
    "                self.conv2 = SigmaConv(args, 32, 64, 5, 2, 3)\n",
    "                self.view1 = SigmaView((64, 4, 4), 64 * 4 * 4)\n",
    "                self.fc1 = SigmaLinear(args, 64 * 4 * 4, 512)\n",
    "                self.fc2 = SigmaLinear(args, 512, 10)\n",
    "                \n",
    "        self.forward_params = list()\n",
    "        self.backward_params = list()\n",
    "        for layer in [self.conv1, self.conv2, self.fc1, self.fc2]:\n",
    "            forward_params, backward_params = layer.get_parameters()\n",
    "            self.forward_params += forward_params\n",
    "            self.backward_params += backward_params\n",
    "\n",
    "    def forward(self, x, detach_grad=False, return_activations=True):   \n",
    "        # x = self.LN1(x)\n",
    "        a1 = self.conv1(x, detach_grad)\n",
    "        a2 = self.conv2(a1, detach_grad)\n",
    "        a2 = self.view1(a2, detach_grad)\n",
    "        a3 = self.fc1(a2, detach_grad)\n",
    "        a4 = self.fc2(a3, detach_grad)\n",
    "        return [a1, a2, a3, a4]\n",
    "        \n",
    "    def reverse(self, target, detach_grad=True, return_activations=True):\n",
    "        if target.shape == torch.Size([10]): \n",
    "            target = F.one_hot(target, num_classes=10).float().to(target.device)\n",
    "        b3 = self.fc2.reverse(target, detach_grad)\n",
    "        b2 = self.fc1.reverse(b3, detach_grad)\n",
    "        b2 = self.view1.reverse(b2, detach_grad)\n",
    "        b1 = self.conv2.reverse(b2, detach_grad)\n",
    "        return [b1, b2, b3, target]\n",
    "\n",
    "\n",
    "class SigmaLoss(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SigmaLoss, self).__init__()\n",
    "        self.args = args\n",
    "        self.final_criteria = nn.CrossEntropyLoss()\n",
    "        self.local_criteria = compute_SCL_loss\n",
    "        self.method = args.method\n",
    "        \n",
    "    def forward(self, activations, signals, target, method=\"final\"):\n",
    "        if method == \"local\":\n",
    "            loss = list()\n",
    "            for act, sig in zip(activations[:-1], signals[:-1]):\n",
    "                loss += [self.local_criteria(act, sig, target)]\n",
    "            loss += [self.final_criteria(activations[-1], target)]\n",
    "            return sum(loss), loss[-1].item()\n",
    "        elif method == \"final\":\n",
    "            loss = self.final_criteria(activations[-1], target) * 1.1 - 0.1\n",
    "            return loss, loss.item()\n",
    "        \n",
    "model = SigmaModel_SimpleCNN(args)\n",
    "model.to(device)\n",
    "if args.optimizer == \"SGD\": \n",
    "    forward_optimizer = optim.SGD(model.forward_params, lr=args.lr)\n",
    "    backward_optimizer = optim.SGD(model.forward_params, lr=args.lr)\n",
    "elif args.optimizer == \"RMSprop\": forward_optimizer = optim.RMSprop(model.forward_params, lr=args.lr, weight_decay=0)\n",
    "elif args.optimizer == \"Adam\": forward_optimizer = optim.Adam(model.forward_params, lr=args.lr)\n",
    "criteria = SigmaLoss(args)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    signals = model.reverse(torch.Tensor([0,1,2,3,4,5,6,7,8,9]).long().to(device), return_activations=True)\n",
    "    \n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"No LN1\")\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "    \n",
    "    train_loss, train_counter = 0, 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx > 100: continue\n",
    "        if args.method == \"SIGMA\":\n",
    "            activations = model(data.to(device), detach_grad=True)\n",
    "            signals = model.reverse(torch.Tensor([0,1,2,3,4,5,6,7,8,9]).long().to(device), detach_grad=True)\n",
    "            loss, loss_item = criteria(activations, signals, target.to(device), method=\"local\")\n",
    "        elif args.method == \"BP\":\n",
    "            activations = model(data.to(device), detach_grad=False)\n",
    "            loss, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "        forward_optimizer.zero_grad(), backward_optimizer.zero_grad(), loss.backward()\n",
    "        gradient_centralization(model), forward_optimizer.step(), backward_optimizer.step()\n",
    "        train_loss += loss_item * len(data)\n",
    "        train_counter += len(data)\n",
    "\n",
    "    wandb.log({'train_loss': train_loss / train_counter}, step=epoch)\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx > 100: continue\n",
    "        activations = model(data.to(device), detach_grad=True)\n",
    "        loss, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "        forward_optimizer.zero_grad(), loss.backward(), forward_optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    val_correct, val_loss, val_counter = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            val_counter += len(data)\n",
    "            if args.method == \"SIGMA\":\n",
    "                activations = model(data.to(device), detach_grad=True)\n",
    "                _, loss_item = criteria(activations, signals, target.to(device), method=\"local\")\n",
    "                \n",
    "            elif args.method == \"BP\":\n",
    "                activations = model(data.to(device), detach_grad=True)\n",
    "                _, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "            prediction = activations[-1].detach()\n",
    "            _, predicted = torch.max(prediction, 1)\n",
    "            val_correct += (predicted == target.to(device)).sum().item()\n",
    "            val_loss += loss_item * len(data)\n",
    "\n",
    "    wandb.log({'val_loss': val_loss / val_counter, \n",
    "               'val_acc': val_correct / val_counter, \n",
    "               }, step=epoch)\n",
    "    \n",
    "    print(f\"\"\"Epoch {epoch} | train loss {train_loss / train_counter:.4f} | val loss {val_loss / val_counter:.4f} | val acc {100 * val_correct / val_counter:.4f}\"\"\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), f'./saved_models/{run_name}-{time_stamp}.pt')\n",
    "        \n",
    "\n",
    "# Eval on Test Set by loading the best model \n",
    "model.load_state_dict(torch.load(f'./saved_models/{run_name}-{time_stamp}.pt'))\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "test_loss, test_counter = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        outputs = model(data.to(device), detach_grad=False)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == target.to(device)).sum().item()\n",
    "        loss, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "        test_loss += loss_item * len(data)\n",
    "        test_counter += len(data)\n",
    "\n",
    "wandb.log({'test_loss': test_loss / test_counter,\n",
    "ｃｖ\n",
    "print(f'Epoch: {epoch}, Test Accuracy: {100 * correct / test_counter:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51df049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 16, 16]) torch.Size([10, 32, 32, 32])\n",
      "torch.Size([64, 4096]) torch.Size([10, 64, 8, 8])\n",
      "torch.Size([64, 128]) torch.Size([10, 128])\n",
      "torch.Size([64, 10]) torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "for a, s in zip(activations, signals):\n",
    "    print(a.shape, s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d937c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 0 | train loss 2.1706 | val loss 1.7251 | val acc 38.4000\n",
    "Epoch 1 | train loss 1.9300 | val loss 1.5896 | val acc 44.4500\n",
    "Epoch 2 | train loss 1.8217 | val loss 1.4883 | val acc 47.6600\n",
    "Epoch 3 | train loss 1.7205 | val loss 1.4662 | val acc 48.2700\n",
    "Epoch 4 | train loss 1.6620 | val loss 1.3580 | val acc 52.1400\n",
    "\n",
    "Epoch 5 | train loss 1.5822 | val loss 1.3429 | val acc 53.0200\n",
    "Epoch 6 | train loss 1.5124 | val loss 1.3322 | val acc 52.9600\n",
    "Epoch 7 | train loss 1.4301 | val loss 1.2645 | val acc 55.5300\n",
    "Epoch 8 | train loss 1.4169 | val loss 1.2650 | val acc 55.7300\n",
    "Epoch 9 | train loss 1.3360 | val loss 1.2396 | val acc 56.5400\n",
    "\n",
    "Epoch 10 | train loss 1.3369 | val loss 1.2339 | val acc 57.2100\n",
    "Epoch 11 | train loss 1.3077 | val loss 1.2344 | val acc 57.2000\n",
    "Epoch 12 | train loss 1.2832 | val loss 1.2064 | val acc 58.1100\n",
    "Epoch 13 | train loss 1.2695 | val loss 1.2016 | val acc 58.7200\n",
    "Epoch 14 | train loss 1.2429 | val loss 1.1799 | val acc 59.7700\n",
    "\n",
    "Epoch 15 | train loss 1.2381 | val loss 1.1819 | val acc 59.5900\n",
    "Epoch 16 | train loss 1.2267 | val loss 1.1791 | val acc 59.5400\n",
    "Epoch 17 | train loss 1.2239 | val loss 1.1724 | val acc 59.5000\n",
    "Epoch 18 | train loss 1.1911 | val loss 1.1605 | val acc 60.5000\n",
    "Epoch 19 | train loss 1.1702 | val loss 1.1587 | val acc 60.6300\n",
    "Epoch 20 | train loss 1.1602 | val loss 1.1574 | val acc 60.8900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be35079",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 0 | train loss 2.1313 | val loss 1.7911 | val acc 35.1500\n",
    "  2%|▏         | 2/100 [00:26<21:38, 13.25s/it]\n",
    "Epoch 1 | train loss 1.6918 | val loss 1.5604 | val acc 44.5300\n",
    "  3%|▎         | 3/100 [00:39<21:30, 13.30s/it]\n",
    "Epoch 2 | train loss 1.5431 | val loss 1.4494 | val acc 48.9800\n",
    "  4%|▍         | 4/100 [00:52<21:11, 13.24s/it]\n",
    "Epoch 3 | train loss 1.4475 | val loss 1.3936 | val acc 50.8200\n",
    "  5%|▌         | 5/100 [01:06<20:56, 13.22s/it]\n",
    "Epoch 4 | train loss 1.4169 | val loss 1.3353 | val acc 53.3300\n",
    "  6%|▌         | 6/100 [01:19<20:36, 13.15s/it]\n",
    "Epoch 5 | train loss 1.3502 | val loss 1.2823 | val acc 55.4500\n",
    "  7%|▋         | 7/100 [01:32<20:28, 13.21s/it]\n",
    "Epoch 6 | train loss 1.3133 | val loss 1.2575 | val acc 57.4800\n",
    "  8%|▊         | 8/100 [01:45<20:23, 13.30s/it]\n",
    "Epoch 7 | train loss 1.2808 | val loss 1.2338 | val acc 58.1700\n",
    "  9%|▉         | 9/100 [01:59<20:06, 13.26s/it]\n",
    "Epoch 8 | train loss 1.2644 | val loss 1.2085 | val acc 59.1500\n",
    " 10%|█         | 10/100 [02:12<19:51, 13.24s/it]\n",
    "Epoch 9 | train loss 1.2249 | val loss 1.2015 | val acc 60.5500\n",
    " 11%|█         | 11/100 [02:25<19:33, 13.19s/it]\n",
    "Epoch 10 | train loss 1.2096 | val loss 1.1854 | val acc 61.0400\n",
    " 12%|█▏        | 12/100 [02:38<19:22, 13.21s/it]\n",
    "Epoch 11 | train loss 1.2114 | val loss 1.1818 | val acc 61.3400\n",
    " 13%|█▎        | 13/100 [02:51<19:07, 13.19s/it]\n",
    "Epoch 12 | train loss 1.1965 | val loss 1.1885 | val acc 62.0300\n",
    " 14%|█▍        | 14/100 [03:04<18:47, 13.11s/it]\n",
    "Epoch 13 | train loss 1.1937 | val loss 1.1811 | val acc 61.8700\n",
    " 15%|█▌        | 15/100 [03:18<18:41, 13.20s/it]\n",
    "Epoch 14 | train loss 1.2066 | val loss 1.1872 | val acc 62.3500\n",
    " 16%|█▌        | 16/100 [03:31<18:22, 13.12s/it]\n",
    "Epoch 15 | train loss 1.1988 | val loss 1.1774 | val acc 62.9200\n",
    " 17%|█▋        | 17/100 [03:44<18:10, 13.14s/it]\n",
    "Epoch 16 | train loss 1.1958 | val loss 1.1849 | val acc 61.6400\n",
    " 18%|█▊        | 18/100 [03:57<17:55, 13.12s/it]\n",
    "Epoch 17 | train loss 1.2015 | val loss 1.1870 | val acc 63.2400\n",
    " 19%|█▉        | 19/100 [04:10<17:37, 13.06s/it]\n",
    "Epoch 18 | train loss 1.1976 | val loss 1.1970 | val acc 63.2700\n",
    " 20%|██        | 20/100 [04:23<17:20, 13.01s/it]\n",
    "Epoch 19 | train loss 1.1864 | val loss 1.1861 | val acc 63.4800\n",
    " 21%|██        | 21/100 [04:36<17:05, 12.98s/it]\n",
    "Epoch 20 | train loss 1.1922 | val loss 1.2039 | val acc 62.8200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
