{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 234, Loss: 1.432\n",
      "Epoch: 0, Test Accuracy: 75.85%\n",
      "Epoch: 1, Batch: 234, Loss: 1.205\n",
      "Epoch: 1, Test Accuracy: 79.66%\n",
      "Epoch: 2, Batch: 234, Loss: 1.035\n",
      "Epoch: 2, Test Accuracy: 81.43%\n",
      "Epoch: 3, Batch: 234, Loss: 0.861\n",
      "Epoch: 3, Test Accuracy: 82.39%\n",
      "Epoch: 4, Batch: 234, Loss: 0.741\n",
      "Epoch: 4, Test Accuracy: 83.1%\n",
      "Epoch: 5, Batch: 234, Loss: 0.706\n",
      "Epoch: 5, Test Accuracy: 83.67%\n",
      "Epoch: 6, Batch: 234, Loss: 0.583\n",
      "Epoch: 6, Test Accuracy: 84.08%\n",
      "Epoch: 7, Batch: 234, Loss: 0.763\n",
      "Epoch: 7, Test Accuracy: 84.28%\n",
      "Epoch: 8, Batch: 234, Loss: 0.726\n",
      "Epoch: 8, Test Accuracy: 84.67%\n",
      "Epoch: 9, Batch: 234, Loss: 0.561\n",
      "Epoch: 9, Test Accuracy: 84.91%\n",
      "Epoch: 10, Batch: 234, Loss: 0.526\n",
      "Epoch: 10, Test Accuracy: 85.23%\n",
      "Epoch: 11, Batch: 234, Loss: 0.573\n",
      "Epoch: 11, Test Accuracy: 85.33%\n",
      "Epoch: 12, Batch: 234, Loss: 0.483\n",
      "Epoch: 12, Test Accuracy: 85.61%\n",
      "Epoch: 13, Batch: 234, Loss: 0.523\n",
      "Epoch: 13, Test Accuracy: 85.71%\n",
      "Epoch: 14, Batch: 234, Loss: 0.701\n",
      "Epoch: 14, Test Accuracy: 85.96%\n",
      "Epoch: 15, Batch: 234, Loss: 0.533\n",
      "Epoch: 15, Test Accuracy: 86.03%\n",
      "Epoch: 16, Batch: 234, Loss: 0.525\n",
      "Epoch: 16, Test Accuracy: 86.21%\n",
      "Epoch: 17, Batch: 234, Loss: 0.438\n",
      "Epoch: 17, Test Accuracy: 86.26%\n",
      "Epoch: 18, Batch: 234, Loss: 0.373\n",
      "Epoch: 18, Test Accuracy: 86.47%\n",
      "Epoch: 19, Batch: 234, Loss: 0.518\n",
      "Epoch: 19, Test Accuracy: 86.49%\n",
      "Epoch: 20, Batch: 234, Loss: 0.412\n",
      "Epoch: 20, Test Accuracy: 86.57%\n",
      "Epoch: 21, Batch: 234, Loss: 0.467\n",
      "Epoch: 21, Test Accuracy: 86.67%\n",
      "Epoch: 22, Batch: 234, Loss: 0.447\n",
      "Epoch: 22, Test Accuracy: 86.88%\n",
      "Epoch: 23, Batch: 234, Loss: 0.528\n",
      "Epoch: 23, Test Accuracy: 86.86%\n",
      "Epoch: 24, Batch: 234, Loss: 0.487\n",
      "Epoch: 24, Test Accuracy: 86.94%\n",
      "Epoch: 25, Batch: 234, Loss: 0.440\n",
      "Epoch: 25, Test Accuracy: 87.04%\n",
      "Epoch: 26, Batch: 234, Loss: 0.528\n",
      "Epoch: 26, Test Accuracy: 87.15%\n",
      "Epoch: 27, Batch: 234, Loss: 0.658\n",
      "Epoch: 27, Test Accuracy: 87.15%\n",
      "Epoch: 28, Batch: 234, Loss: 0.598\n",
      "Epoch: 28, Test Accuracy: 87.24%\n",
      "Epoch: 29, Batch: 234, Loss: 0.779\n",
      "Epoch: 29, Test Accuracy: 87.3%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(2024)\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "# Define the forward and backward models\n",
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ForwardModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, HIDDEN_DIM)\n",
    "        self.fc2 = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
    "        self.fc3 = nn.Linear(HIDDEN_DIM, 10)\n",
    "        \n",
    "        self.fc3.weight.data.zero_()\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc2.bias.data.zero_()\n",
    "        self.fc3.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, s2=None):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        a1 = F.elu(self.fc1(x))\n",
    "        a2 = F.elu(self.fc2(a1.detach()))\n",
    "        a3 = self.fc3(a2.detach())\n",
    "    \n",
    "        if s2 is not None:\n",
    "            s2_recon = self.fc3(s2.detach())\n",
    "            return a1, a2, a3, s2_recon\n",
    "        else:\n",
    "            return a1, a2, a3, None\n",
    "\n",
    "# # Define the loss functions\n",
    "# def sigma_loss(a3, t):\n",
    "#     loss3 = F.mse_loss(a3, torch.nn.functional.one_hot(t, num_classes=10).float().to(t.device))\n",
    "#     return loss3\n",
    "\n",
    "# Define the loss function\n",
    "def sigma_loss(a3, t):\n",
    "    # num_classes = 10\n",
    "    # t_one_hot = F.one_hot(t, num_classes).float()\n",
    "    # loss3 = F.binary_cross_entropy_with_logits(a3, t_one_hot)\n",
    "    loss = criteria(a3, t)\n",
    "    return loss\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=HIDDEN_DIM, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=HIDDEN_DIM, shuffle=False)\n",
    "\n",
    "# Initialize the models\n",
    "forward_model = ForwardModel()\n",
    "\n",
    "# Define the optimizers\n",
    "forward_optimizer = optim.SGD(forward_model.parameters(), lr=0.03, momentum=0.5)\n",
    "\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(30):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # Forward pass\n",
    "        a1, a2, a3, s2_recon = forward_model(data)\n",
    "        # Compute losses\n",
    "        loss = criteria(a3, target)\n",
    "\n",
    "        # Update parameters\n",
    "        forward_optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        forward_optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "    print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.3f}')\n",
    "\n",
    "    # Evaluate on test set\n",
    "    forward_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            _, _, outputs, _ = forward_model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Test Accuracy: {100 * correct / total}%')\n",
    "    forward_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0023,  0.0237,  0.0337,  ..., -0.0043, -0.0330, -0.0205],\n",
       "        [-0.0297,  0.0216, -0.0344,  ...,  0.0200, -0.0087, -0.0302],\n",
       "        [ 0.0146, -0.0248,  0.0243,  ...,  0.0059,  0.0279, -0.0065],\n",
       "        ...,\n",
       "        [-0.0246, -0.0254,  0.0223,  ...,  0.0059, -0.0134,  0.0138],\n",
       "        [ 0.0267, -0.0255, -0.0024,  ..., -0.0045, -0.0024,  0.0087],\n",
       "        [-0.0053, -0.0010,  0.0096,  ...,  0.0314, -0.0324,  0.0099]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_model.fc1.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
