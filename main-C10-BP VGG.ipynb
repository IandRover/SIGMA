{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffa0c9f-8276-4e73-b6a8-bf33d01039d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = \"dcf9600e0485401cbb0ddbb0f7be1c70f96b32ef\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "import wandb\n",
    "from sigma_layer_vgg import SigmaLinear, SigmaConv, SigmaView\n",
    "from utils import get_dataset, gradient_centralization, normalize_along_axis, get_activation_function, compute_SCL_loss\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f367862f-05b5-4c98-b3be-7a36a686df88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: CIFAR10_BP_conv32-actelu_SGD_0.03_2023\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "No LN1\n",
      "Epoch 0 | train loss 1.6276 | val loss 1.1562 | val acc 59.7500\n",
      "Epoch 1 | train loss 1.3218 | val loss 1.0831 | val acc 63.4800\n",
      "Epoch 2 | train loss 1.2171 | val loss 0.9938 | val acc 66.7500\n",
      "Epoch 3 | train loss 1.2285 | val loss 0.9936 | val acc 66.5400\n",
      "Epoch 4 | train loss 1.2537 | val loss 1.0988 | val acc 64.9400\n",
      "Epoch 5 | train loss 1.2443 | val loss 1.0495 | val acc 67.1800\n",
      "Epoch 6 | train loss 1.2933 | val loss 1.1262 | val acc 66.5300\n",
      "Epoch 7 | train loss 1.2944 | val loss 1.0785 | val acc 67.0800\n",
      "Epoch 8 | train loss 1.2404 | val loss 1.1649 | val acc 65.6700\n",
      "Epoch 9 | train loss 1.2683 | val loss 1.2692 | val acc 64.7800\n",
      "Epoch 10 | train loss 1.2894 | val loss 1.2406 | val acc 64.8900\n",
      "Epoch 11 | train loss 1.3537 | val loss 1.2360 | val acc 66.0000\n",
      "Epoch 12 | train loss 1.3155 | val loss 1.2241 | val acc 67.5600\n",
      "Epoch 13 | train loss 1.2746 | val loss 1.2009 | val acc 66.4200\n",
      "Epoch 14 | train loss 1.3570 | val loss 1.1953 | val acc 67.6100\n",
      "Epoch 15 | train loss 1.3189 | val loss 1.2205 | val acc 66.1800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 166\u001b[0m\n\u001b[1;32m    164\u001b[0m val_correct, val_loss, val_counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m    165\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m val_loader:\n\u001b[1;32m    167\u001b[0m         val_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m    168\u001b[0m         \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSIGMA\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx]]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mto_tensor(pic)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:166\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    165\u001b[0m mode_to_nptype \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint32, \u001b[39m\"\u001b[39m\u001b[39mI;16\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint16, \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mfloat32}\n\u001b[0;32m--> 166\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray(pic, mode_to_nptype\u001b[39m.\u001b[39mget(pic\u001b[39m.\u001b[39mmode, np\u001b[39m.\u001b[39muint8), copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:701\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    700\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 701\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    702\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e, (\u001b[39mMemoryError\u001b[39;00m, \u001b[39mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:771\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    769\u001b[0m data \u001b[39m=\u001b[39m []\n\u001b[1;32m    770\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     l, s, d \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mencode(bufsize)\n\u001b[1;32m    772\u001b[0m     data\u001b[39m.\u001b[39mappend(d)\n\u001b[1;32m    773\u001b[0m     \u001b[39mif\u001b[39;00m s:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "# Training scheme group\n",
    "method_parser = parser.add_argument_group(\"Method\")\n",
    "method_parser.add_argument('--method', type=str, default='BP', choices=['SIGMA', 'BP', 'FA'])\n",
    "method_parser.add_argument('--architecture', type=str, default='lenet', choices=['lenet', 'vgg'])\n",
    "method_parser.add_argument('--actfunc', type=str, default='elu', choices=['tanh', 'elu', 'relu'])\n",
    "method_parser.add_argument('--conv_dim', type=int, default=32, choices=[32, 64])\n",
    "# Dataset group\n",
    "dataset_parser = parser.add_argument_group('Dataset')\n",
    "dataset_parser.add_argument('--dataset', type=str, default='CIFAR10', choices=['MNIST', 'CIFAR10'])\n",
    "dataset_parser.add_argument('--batchsize', type=int, default=128)\n",
    "dataset_parser.add_argument('--splitratio', type=float, default=0.2)\n",
    "# Training group # LR, optimizer, weight_decay, momentum\n",
    "training_parser = parser.add_argument_group('Training')\n",
    "training_parser.add_argument('--epochs', type=int, default=100)\n",
    "training_parser.add_argument('--lr', type=float, default=0.03)\n",
    "training_parser.add_argument('--optimizer', type=str, default='SGD', choices=['RMSprop', 'Adam', 'SGD'])\n",
    "# Seed group\n",
    "seed_parser = parser.add_argument_group('Seed')\n",
    "seed_parser.add_argument('--seed', type=int, default=2023)\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "# Set run_name\n",
    "run_name = f\"{args.dataset}_{args.method}_conv{args.conv_dim}-act{args.actfunc}_{args.optimizer}_{args.lr}_{args.seed}\"\n",
    "time_stamp = datetime.datetime.now().strftime(\"%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Set wandb\n",
    "wandb.init(\n",
    "    project=\"opt-sigma\",\n",
    "    name=run_name,\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"algorithm\": args.method,\n",
    "    \"architecture\": \"SimpleCNN\",\n",
    "    \"dataset\": args.dataset,\n",
    "    \"epochs\": args.epochs,\n",
    "    \"lr\": args.lr,\n",
    "    \"optimizer\": args.optimizer,\n",
    "    \"seed\": args.seed,\n",
    "    \"conv_dim\": args.conv_dim,\n",
    "    \"actfunc\": args.actfunc,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Run name: {run_name}\")\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(args.seed), np.random.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda\")\n",
    "\n",
    "# Get dataset\n",
    "train_loader, val_loader, test_loader = get_dataset(args)\n",
    "\n",
    "class SigmaModel_SimpleCNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SigmaModel_SimpleCNN, self).__init__()\n",
    "        if args.dataset == \"CIFAR10\":\n",
    "            # self, args, in_channels, out_channels, conv_kernel, conv_stride, conv_padding, pool_kernel, pool_stride, pool_padding):\n",
    "            self.conv1 = SigmaConv(args, 3, 128, 3, 1, 1, 2, 2, 0)\n",
    "            self.conv2 = SigmaConv(args, 128, 128, 3, 1, 1, 2, 2, 0)\n",
    "            self.conv3 = SigmaConv(args, 128, 256, 3, 1, 1, 2, 2, 0)\n",
    "            self.conv4 = SigmaConv(args, 256, 256, 3, 1, 1, 2, 2, 0)\n",
    "            self.conv5 = SigmaConv(args, 256, 512, 3, 1, 1, 2, 2, 0)\n",
    "            self.view1 = SigmaView((512, 4, 4), 512 * 4 * 4)\n",
    "            self.fc1 = SigmaLinear(args, 512 * 4 * 4, 10)\n",
    "                \n",
    "        self.forward_params = list()\n",
    "        self.backward_params = list()\n",
    "        for layer in [self.conv1, self.conv2, self.fc1, self.fc2]:\n",
    "            forward_params, backward_params = layer.get_parameters()\n",
    "            self.forward_params += forward_params\n",
    "            self.backward_params += backward_params\n",
    "\n",
    "    def forward(self, x, detach_grad=False, return_activations=True):   \n",
    "        a1 = self.conv1(x, detach_grad)\n",
    "        a2 = self.conv2(a1, detach_grad)\n",
    "        a3 = self.conv3(a2, detach_grad)\n",
    "        a4 = self.conv4(a3, detach_grad)\n",
    "        a5 = self.conv5(a4, detach_grad)\n",
    "        a5 = self.view1(a5, detach_grad)\n",
    "        a6 = self.fc1(a5, detach_grad)\n",
    "        return [a1, a2, a3, a4, a5, a6]\n",
    "\n",
    "        \n",
    "    def reverse(self, target, detach_grad=True, return_activations=True):\n",
    "        if target.shape == torch.Size([10]): \n",
    "            target = F.one_hot(target, num_classes=10).float().to(target.device)\n",
    "        b5 = self.fc1.reverse(target, detach_grad)\n",
    "        b5 = self.view1.reverse(b5, detach_grad)\n",
    "        b4 = self.conv5.reverse(b5, detach_grad)\n",
    "        b3 = self.conv4.reverse(b4, detach_grad)\n",
    "        b2 = self.conv3.reverse(b3, detach_grad)\n",
    "        b1 = self.conv2.reverse(b2, detach_grad)\n",
    "        return [b1, b2, b3, b4, b5, target]\n",
    "\n",
    "class SigmaLoss(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SigmaLoss, self).__init__()\n",
    "        self.args = args\n",
    "        self.final_criteria = nn.CrossEntropyLoss()\n",
    "        self.local_criteria = compute_SCL_loss\n",
    "        self.method = args.method\n",
    "        \n",
    "    def forward(self, activations, signals, target, method=\"final\"):\n",
    "        if method == \"local\":\n",
    "            loss = list()\n",
    "            for act, sig in zip(activations[:-1], signals[:-1]):\n",
    "                loss += [self.local_criteria(act, sig, target)]\n",
    "            loss += [self.final_criteria(activations[-1], target)]\n",
    "            return sum(loss), loss[-1].item()\n",
    "        elif method == \"final\":\n",
    "            loss = self.final_criteria(activations[-1], target)\n",
    "            return loss, loss.item()\n",
    "        \n",
    "model = SigmaModel_SimpleCNN(args)\n",
    "model.to(device)\n",
    "if args.optimizer == \"SGD\": \n",
    "    forward_optimizer = optim.SGD(model.forward_params, lr=0.03, momentum=0.9, weight_decay=0.0001)\n",
    "    # backward_optimizer = optim.SGD(model.forward_params, lr=args.lr)\n",
    "elif args.optimizer == \"Adam\": \n",
    "    forward_optimizer = optim.Adam(model.forward_params)\n",
    "    backward_optimizer = optim.Adam(model.forward_params)\n",
    "criteria = SigmaLoss(args)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    signals = model.reverse(torch.Tensor([0,1,2,3,4,5,6,7,8,9]).long().to(device), return_activations=True)\n",
    "    \n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"No LN1\")\n",
    "for epoch in range(args.epochs):\n",
    "    \n",
    "    train_loss, train_counter = 0, 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # if batch_idx > 100: continue\n",
    "        \n",
    "        if args.method == \"SIGMA\":\n",
    "            activations = model(data.to(device), detach_grad=True)\n",
    "            signals = model.reverse(torch.Tensor([0,1,2,3,4,5,6,7,8,9]).long().to(device), detach_grad=True)\n",
    "            loss, loss_item = criteria(activations, signals, target.to(device), method=\"local\")\n",
    "        elif args.method == \"BP\":\n",
    "            activations = model(data.to(device), detach_grad=False)\n",
    "            loss, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "        forward_optimizer.zero_grad(), loss.backward(), forward_optimizer.step()\n",
    "        train_loss += loss_item * len(data)\n",
    "        train_counter += len(data)\n",
    "\n",
    "    wandb.log({'train_loss': train_loss / train_counter}, step=epoch)\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx > 100: continue\n",
    "        activations = model(data.to(device), detach_grad=True)\n",
    "        loss, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "        forward_optimizer.zero_grad(), loss.backward(), forward_optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    val_correct, val_loss, val_counter = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            val_counter += len(data)\n",
    "            if args.method == \"SIGMA\":\n",
    "                activations = model(data.to(device), detach_grad=True)\n",
    "                _, loss_item = criteria(activations, signals, target.to(device), method=\"local\")\n",
    "                \n",
    "            elif args.method == \"BP\":\n",
    "                activations = model(data.to(device), detach_grad=True)\n",
    "                _, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "            prediction = activations[-1].detach()\n",
    "            _, predicted = torch.max(prediction, 1)\n",
    "            val_correct += (predicted == target.to(device)).sum().item()\n",
    "            val_loss += loss_item * len(data)\n",
    "\n",
    "    wandb.log({'val_loss': val_loss / val_counter, \n",
    "               'val_acc': val_correct / val_counter, \n",
    "               }, step=epoch)\n",
    "    \n",
    "    print(f\"\"\"Epoch {epoch} | train loss {train_loss / train_counter:.4f} | val loss {val_loss / val_counter:.4f} | val acc {100 * val_correct / val_counter:.4f}\"\"\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), f'./saved_models/{run_name}-{time_stamp}.pt')\n",
    "        \n",
    "\n",
    "# Eval on Test Set by loading the best model \n",
    "model.load_state_dict(torch.load(f'./saved_models/{run_name}-{time_stamp}.pt'))\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "test_loss, test_counter = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        outputs = model(data.to(device), detach_grad=False)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == target.to(device)).sum().item()\n",
    "        loss, loss_item = criteria(activations, signals, target.to(device), method=\"final\")\n",
    "        test_loss += loss_item * len(data)\n",
    "        test_counter += len(data)\n",
    "\n",
    "wandb.log({'test_loss': test_loss / test_counter,\n",
    "           'test_acc': 100 * correct / test_counter})\n",
    "\n",
    "print(f'Epoch: {epoch}, Test Accuracy: {100 * correct / test_counter:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Cropping (edge)\n",
    "# transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(3 * 0.2023, 3 * 0.1994, 3 * 0.2010)) # Following pl_bolt's\n",
    "                                        \n",
    "# Epoch 0 | train loss 1.4767 | val loss 1.0709 | val acc 62.5100\n",
    "# Epoch 1 | train loss 1.0998 | val loss 0.9122 | val acc 68.3900\n",
    "# Epoch 2 | train loss 0.9462 | val loss 0.8498 | val acc 70.5800\n",
    "# Epoch 3 | train loss 0.8750 | val loss 0.8037 | val acc 72.3100\n",
    "# Epoch 4 | train loss 0.8145 | val loss 0.7622 | val acc 73.4700\n",
    "# Epoch 5 | train loss 0.7637 | val loss 0.7678 | val acc 72.9200\n",
    "# Epoch 6 | train loss 0.7437 | val loss 0.7297 | val acc 74.7100\n",
    "# Epoch 7 | train loss 0.7246 | val loss 0.7414 | val acc 74.4800\n",
    "# Epoch 8 | train loss 0.6919 | val loss 0.7192 | val acc 75.2600\n",
    "# Epoch 9 | train loss 0.6813 | val loss 0.7395 | val acc 74.7300\n",
    "# Epoch 10 | train loss 0.6572 | val loss 0.7179 | val acc 75.7500\n",
    "# Epoch 11 | train loss 0.6289 | val loss 0.7234 | val acc 75.7500\n",
    "# Epoch 12 | train loss 0.6311 | val loss 0.7124 | val acc 76.4500\n",
    "# Epoch 13 | train loss 0.6076 | val loss 0.7303 | val acc 75.5700\n",
    "# Epoch 14 | train loss 0.6110 | val loss 0.7216 | val acc 75.9600\n",
    "# Epoch 15 | train loss 0.5847 | val loss 0.7151 | val acc 75.9800\n",
    "# Epoch 16 | train loss 0.5721 | val loss 0.7057 | val acc 76.8200\n",
    "# Epoch 17 | train loss 0.5608 | val loss 0.7082 | val acc 76.3500\n",
    "# Epoch 18 | train loss 0.5597 | val loss 0.7072 | val acc 77.0000\n",
    "# Epoch 19 | train loss 0.5428 | val loss 0.6865 | val acc 77.6100\n",
    "# Epoch 20 | train loss 0.5215 | val loss 0.7228 | val acc 76.8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d937c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epoch 0 | train loss 1.6212 | val loss 1.2239 | val acc 57.7800\n",
    "# Epoch 1 | train loss 1.1105 | val loss 0.9573 | val acc 67.1100\n",
    "# Epoch 2 | train loss 0.9249 | val loss 0.8443 | val acc 70.5500\n",
    "# Epoch 3 | train loss 0.8030 | val loss 0.7778 | val acc 72.5400\n",
    "# Epoch 4 | train loss 0.7149 | val loss 0.7120 | val acc 75.0400\n",
    "# Epoch 5 | train loss 0.6382 | val loss 0.6874 | val acc 75.8700\n",
    "# Epoch 6 | train loss 0.5760 | val loss 0.6636 | val acc 76.4500\n",
    "# Epoch 7 | train loss 0.5212 | val loss 0.6519 | val acc 77.5800\n",
    "# Epoch 8 | train loss 0.4668 | val loss 0.6548 | val acc 77.4300\n",
    "# Epoch 9 | train loss 0.4243 | val loss 0.6586 | val acc 77.5500\n",
    "# Epoch 10 | train loss 0.3872 | val loss 0.6611 | val acc 78.0400\n",
    "# Epoch 11 | train loss 0.3390 | val loss 0.6800 | val acc 77.9200\n",
    "# Epoch 12 | train loss 0.3089 | val loss 0.7055 | val acc 77.8300\n",
    "# Epoch 13 | train loss 0.2707 | val loss 0.7307 | val acc 77.7800\n",
    "# Epoch 14 | train loss 0.2408 | val loss 0.7463 | val acc 77.9100\n",
    "# Epoch 15 | train loss 0.2150 | val loss 0.7790 | val acc 78.4800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d3ce4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
